# ğŸ¦· Assistente de SaÃºde Bucal com Flask + Ollama + Redis

Este Ã© um projeto de assistente virtual de saÃºde bucal, desenvolvido com **Flask**, **Ollama** e **Redis**. Ele foi criado para **orientar usuÃ¡rios sobre cuidados com a saÃºde bucal**, **vender planos odontolÃ³gicos com desconto** e **redirecionar o usuÃ¡rio para telas especÃ­ficas** com base em sua mensagem.

---

## ğŸ§  Tecnologias utilizadas

* **Flask**: framework web responsÃ¡vel por expor a API `/chat`, que processa a entrada do usuÃ¡rio e retorna a resposta.
* **Ollama**: servidor local que executa o modelo de linguagem (LLM `llama3`) para gerar respostas personalizadas com base em contexto.
* **Redis**: utilizado para cache de respostas geradas anteriormente, melhorando a performance.
* **RAG leve (Retrieval-Augmented Generation)**: utiliza um arquivo `documents.json` como base de conhecimento local, sem banco de dados ou vetorizaÃ§Ã£o pesada.

---

## ğŸ’¡ Como funciona

1. O usuÃ¡rio envia uma mensagem (ex: "Quero marcar uma consulta").
2. O sistema verifica se hÃ¡ uma **resposta padrÃ£o** (para agilizar o atendimento).
3. Caso nÃ£o haja, ele consulta o modelo `llama3`, incluindo contexto da base (`documents.json`) para enriquecer a resposta.
4. Se a resposta do modelo contiver termos como `consulta`, `horÃ¡rio`, etc., o sistema adiciona uma rota (`"app_rota": "agendamento"`) e pode incluir links promocionais.
5. A resposta Ã© cacheada no Redis por 1 hora para reutilizaÃ§Ã£o.

---

## ğŸ¯ Objetivo do projeto

Este assistente foi desenvolvido com foco em **direcionar clientes interessados em cuidados odontolÃ³gicos**. Ele ajuda a:

* Coletar informaÃ§Ãµes bÃ¡sicas do usuÃ¡rio.
* Redirecionar para o fluxo de **agendamento de consultas**.
* Promover **planos de saÃºde bucal com desconto**.
* Melhorar a experiÃªncia do usuÃ¡rio com respostas rÃ¡pidas e personalizadas.

---

## ğŸ“ Estrutura esperada

```
project/
â”‚
â”œâ”€â”€ app.py               # API Flask
â”œâ”€â”€ documents.json       # Base de conhecimento textual
â”œâ”€â”€ Dockerfile           # (opcional) build do app
â”œâ”€â”€ docker-compose.yml   # Redis, Ollama, Flask
```

---

## â–¶ï¸ Como rodar com Docker Compose

Certifique-se de ter o modelo `llama3` jÃ¡ baixado e o Ollama funcionando.

```bash
docker compose up --build
```

A API estarÃ¡ disponÃ­vel em: [http://localhost:5000/chat](http://localhost:5000/chat)

---

## ğŸ“Œ Exemplo de requisiÃ§Ã£o

```json
POST /chat
{
  "message": "Quero marcar uma consulta"
}
```

Resposta:

```json
{
  "reply": "Claro! Podemos marcar uma consulta. Informe a especialidade desejada.",
  "app_rota": "agendamento"
}
```

